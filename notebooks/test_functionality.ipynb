{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srossi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import vardl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn.datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = vardl.layers.BayesianLinear(in_features=5, out_features=2, local_reparameterization=True, approx='factorized', nmc_test=1, nmc_train=1)\n",
    "layer1 = vardl.layers.BayesianLinear(in_features=2, out_features=1, local_reparameterization=True, approx='factorized', nmc_test=1, nmc_train=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianLinear(\n",
       "  in_features=5, out_features=2, bias=False, local_repr=True\n",
       "  (prior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "  (q_posterior_W): MatrixGaussianDistribution(approx=factorized)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = nn.Sequential(layer0, layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BayesianLinear(\n",
       "    in_features=5, out_features=2, bias=False, local_repr=True\n",
       "    (prior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "    (q_posterior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "  )\n",
       "  (1): BayesianLinear(\n",
       "    in_features=2, out_features=1, bias=False, local_repr=True\n",
       "    (prior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "    (q_posterior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vardl.models.RegrBayesianNet(architecure=arch, \n",
    "                                     dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegrBayesianNet(\n",
       "  (architecture): Sequential(\n",
       "    (0): BayesianLinear(\n",
       "      in_features=5, out_features=2, bias=False, local_repr=True\n",
       "      (prior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "      (q_posterior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "    )\n",
       "    (1): BayesianLinear(\n",
       "      in_features=2, out_features=1, bias=False, local_repr=True\n",
       "      (prior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "      (q_posterior_W): MatrixGaussianDistribution(approx=factorized)\n",
       "    )\n",
       "  )\n",
       "  (likelihood): Gaussian()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture.0.prior_W._mean False\n",
      "architecture.0.prior_W._logvars False\n",
      "architecture.0.q_posterior_W._mean True\n",
      "architecture.0.q_posterior_W._logvars True\n",
      "architecture.1.prior_W._mean False\n",
      "architecture.1.prior_W._logvars False\n",
      "architecture.1.q_posterior_W._mean True\n",
      "architecture.1.q_posterior_W._logvars True\n",
      "likelihood.log_noise_var True\n"
     ]
    }
   ],
   "source": [
    "for name, par in model.named_parameters():\n",
    "    print(name, par.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, W = sklearn.datasets.make_regression(n_samples=100000, \n",
    "                                 n_features=5, #100\n",
    "                                 n_informative=5, \n",
    "                                 n_targets=1, bias=0,\n",
    "                                 effective_rank=None,\n",
    "                                 noise=np.exp(0),\n",
    "                                 shuffle=False, coef=True, \n",
    "                                 random_state=0)\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "Y = torch.from_numpy(Y.reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, \n",
    "                              drop_last=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = vardl.logger.TensorboardLogger('../work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = vardl.trainer.TrainerRegressor(model=model, \n",
    "                                         train_dataloader=dataloader, \n",
    "                                         test_dataloader=dataloader, \n",
    "                                         optimizer='Adam', \n",
    "                                         optimizer_config={'lr':0.1}, \n",
    "                                         device='cpu', \n",
    "                                         logger=tb_logger,\n",
    "                                         seed=0)\n",
    "trainer_logging_config = {'train_verbose': True, 'train_log_interval':100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trainer.model.likelihood.log_noise_var.requires_grad = False\n",
    "trainer.train_per_iterations(4000, **trainer_logging_config)\n",
    "trainer.model.likelihood.log_noise_var.requires_grad = True\n",
    "trainer.train_per_iterations(1000, **trainer_logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    1   loss=3687969024  dkl=       0  error=99.91  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    2   loss=4564534784  dkl=       0  error=111.15  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    3   loss=4424243200  dkl=       1  error=109.43  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    4   loss=4690185728  dkl=       2  error=112.67  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    5   loss=4212494848  dkl=       3  error=106.78  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    6   loss=4915682816  dkl=       4  error=115.35  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    7   loss=4275648768  dkl=       6  error=107.58  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    8   loss=4129693440  dkl=       8  error=105.73  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=    9   loss=4808464384  dkl=      11  error=114.08  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   10   loss=3998469120  dkl=      14  error=104.03  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   11   loss=3939123456  dkl=      18  error=103.26  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   12   loss=4174313728  dkl=      22  error=106.30  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   13   loss=4411251200  dkl=      26  error=109.27  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   14   loss=4698780672  dkl=      31  error=112.78  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   15   loss=4083626496  dkl=      37  error=105.14  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   16   loss=3836184320  dkl=      43  error=101.90  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   17   loss=3391396096  dkl=      50  error=95.81  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   18   loss=3717593088  dkl=      58  error=100.31  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   19   loss=3534821120  dkl=      66  error=97.82  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   20   loss=3765941760  dkl=      75  error=100.96  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   21   loss=3611162624  dkl=      84  error=98.87  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   22   loss=3330842880  dkl=      94  error=94.95  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   23   loss=3087065856  dkl=     105  error=91.41  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   24   loss=3064179200  dkl=     116  error=91.07  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   25   loss=2534460672  dkl=     128  error=82.83  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   26   loss=2643655680  dkl=     141  error=84.59  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   27   loss=2519069184  dkl=     154  error=82.58  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   28   loss=2190939136  dkl=     168  error=77.01  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   29   loss=2336411904  dkl=     183  error=79.53  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   30   loss=2205737472  dkl=     198  error=77.27  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   31   loss=2128460416  dkl=     214  error=75.90  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   32   loss=1915721728  dkl=     230  error=72.01  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   33   loss=1682864896  dkl=     247  error=67.49  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   34   loss=1406643584  dkl=     265  error=61.71  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   35   loss=1303617664  dkl=     282  error=59.40  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   36   loss=1331123072  dkl=     300  error=60.03  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   37   loss=1157961728  dkl=     318  error=55.99  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   38   loss= 946620736  dkl=     336  error=50.62  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   39   loss=1162655616  dkl=     354  error=56.10  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   40   loss= 861048640  dkl=     372  error=48.28  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   41   loss= 760586240  dkl=     390  error=45.38  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   42   loss= 767444352  dkl=     408  error=45.58  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   43   loss= 612946560  dkl=     425  error=40.73  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   44   loss= 459728768  dkl=     441  error=35.28  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   45   loss= 413485056  dkl=     457  error=33.46  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   46   loss= 340913376  dkl=     471  error=30.38  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   47   loss= 339892096  dkl=     485  error=30.34  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   48   loss= 248263360  dkl=     498  error=25.93  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   49   loss= 225259904  dkl=     510  error=24.70  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   50   loss= 204500304  dkl=     520  error=23.53  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   51   loss= 202788064  dkl=     530  error=23.43  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   52   loss= 139212000  dkl=     539  error=19.42  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   53   loss= 126793416  dkl=     547  error=18.53  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   54   loss= 100927224  dkl=     554  error=16.54  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   55   loss=  87145800  dkl=     560  error=15.37  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   56   loss=  81147488  dkl=     566  error=14.83  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   57   loss=  69961064  dkl=     570  error=13.77  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   58   loss=  61527384  dkl=     574  error=12.92  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   59   loss=  74381768  dkl=     576  error=14.20  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   60   loss=  49059560  dkl=     578  error=11.54  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   61   loss=  47645244  dkl=     579  error=11.37  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   62   loss=  51193376  dkl=     579  error=11.78  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   63   loss=  49218184  dkl=     579  error=11.55  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   64   loss=  42070348  dkl=     578  error=10.68  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   65   loss=  44583484  dkl=     576  error=11.00  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   66   loss=  35685720  dkl=     575  error=9.84  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   67   loss=  38543472  dkl=     573  error=10.23  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   68   loss=  32810424  dkl=     570  error=9.44  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   69   loss=  35112908  dkl=     568  error=9.76  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   70   loss=  30081700  dkl=     566  error=9.04  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   71   loss=  22888862  dkl=     563  error=7.89  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   72   loss=  20475968  dkl=     561  error=7.46  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   73   loss=  21632336  dkl=     558  error=7.67  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   74   loss=  22743054  dkl=     556  error=7.86  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   75   loss=  18000836  dkl=     554  error=7.00  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   76   loss=  18112830  dkl=     552  error=7.02  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   77   loss=  17384646  dkl=     550  error=6.88  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   78   loss=  17087748  dkl=     549  error=6.82  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   79   loss=  13165256  dkl=     547  error=5.99  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   80   loss=  11341205  dkl=     546  error=5.56  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   81   loss=   9546006  dkl=     545  error=5.11  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   82   loss=  10255636  dkl=     545  error=5.29  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   83   loss=   7064601  dkl=     544  error=4.40  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   84   loss=   9313291  dkl=     544  error=5.05  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   85   loss=   8036016  dkl=     544  error=4.69  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   86   loss=   7509170  dkl=     544  error=4.54  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   87   loss=   6645706  dkl=     544  error=4.27  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   88   loss=   7925331  dkl=     544  error=4.66  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   89   loss=   5108522  dkl=     544  error=3.75  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   90   loss=   4883433  dkl=     545  error=3.67  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   91   loss=   5332148  dkl=     545  error=3.83  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   92   loss=   5663829  dkl=     546  error=3.95  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   93   loss=   6116024  dkl=     546  error=4.10  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   94   loss=   4963578  dkl=     547  error=3.70  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   95   loss=   3844750  dkl=     548  error=3.27  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   96   loss=   3831423  dkl=     549  error=3.26  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   97   loss=   4724892  dkl=     549  error=3.61  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   98   loss=   3542752  dkl=     550  error=3.14  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=   99   loss=   4167141  dkl=     551  error=3.40  log_theta_noise_var=-2.00\n",
      "torch.Size([256, 5])\n",
      "torch.Size([1, 256, 2])\n",
      "\u001b[1m\u001b[34mTrain\u001b[0m || iter=  100   loss=   3031352  dkl=     551  error=2.91  log_theta_noise_var=-2.00\n"
     ]
    }
   ],
   "source": [
    "trainer.model.likelihood.log_noise_var.requires_grad = False\n",
    "\n",
    "trainer.train_per_iterations(100, train_log_interval=1, train_verbose=True)\n",
    "\n",
    "#trainer.fit(iterations=1000,test_interval=100, **trainer_logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = vardl.initializer.LSUVInitializer(model, train_dataloader=dataloader, tollerance=0.001, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1835],\n",
       "        [-0.6763],\n",
       "        [ 0.7989],\n",
       "        [-0.4343],\n",
       "        [ 0.1013]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.architecture[0].q_posterior_W.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9163],\n",
       "        [-0.9163],\n",
       "        [-0.9163],\n",
       "        [-0.9163],\n",
       "        [-0.9163]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.architecture[0].q_posterior_W.logvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Variance at layer 0 (iter #34): 1.001\n"
     ]
    }
   ],
   "source": [
    "init.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4114],\n",
       "        [ 0.1680],\n",
       "        [ 0.5070],\n",
       "        [-0.3756],\n",
       "        [ 0.6798]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.architecture[0].q_posterior_W.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9163],\n",
       "        [-0.9163],\n",
       "        [-0.9163],\n",
       "        [-0.9163],\n",
       "        [-0.9163]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.architecture[0].q_posterior_W.logvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
